{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "564f3535-02d3-4be9-865f-28f9882a3cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "import warnings\n",
    "import yaml\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from functions.models import get_ensemble_model, get_linear_model, get_nonlinear_model\n",
    "from functions.models import get_model_explanations, get_age_corrected_model_explanations, correct_age_predictions\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5830289d-4fc2-4234-b84e-64da4f5eef35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sheet_1 = pd.read_excel('./feat_imp/total.xlsx', sheet_name='Sheet1')\n",
    "df_sheet_2 = pd.read_excel('./feat_imp/total.xlsx', sheet_name='Sheet2')\n",
    "df_sheet_3 = pd.read_excel('./feat_imp/total.xlsx', sheet_name='Sheet3')\n",
    "df_sheet_4 = pd.read_excel('./feat_imp/total.xlsx', sheet_name='Sheet4')\n",
    "df_sheet_5 = pd.read_excel('./feat_imp/total.xlsx', sheet_name='Sheet5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2a44c3f-d4ec-4e0b-a7ef-818544b916d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>HCP</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>CamCAN</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>IXI</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Feature</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>Gaussian Process</td>\n",
       "      <td>Gradient Boosting Regressor</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>Gaussian Process</td>\n",
       "      <td>Gradient Boosting Regressor</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>Gaussian Process</td>\n",
       "      <td>Gradient Boosting Regressor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>etiv</td>\n",
       "      <td>1.24636</td>\n",
       "      <td>3.449212</td>\n",
       "      <td>0.108937</td>\n",
       "      <td>7.714287</td>\n",
       "      <td>8.831332</td>\n",
       "      <td>0.72565</td>\n",
       "      <td>4.306448</td>\n",
       "      <td>4.933209</td>\n",
       "      <td>0.225736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lh_accumbens_area</td>\n",
       "      <td>0.039937</td>\n",
       "      <td>0.301591</td>\n",
       "      <td>0.025911</td>\n",
       "      <td>0.391047</td>\n",
       "      <td>0.079653</td>\n",
       "      <td>0.252782</td>\n",
       "      <td>0.492026</td>\n",
       "      <td>0.258993</td>\n",
       "      <td>0.481662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lh_amygdala</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.060219</td>\n",
       "      <td>0.01316</td>\n",
       "      <td>1.233872</td>\n",
       "      <td>1.531566</td>\n",
       "      <td>0.314019</td>\n",
       "      <td>0.48063</td>\n",
       "      <td>1.126055</td>\n",
       "      <td>0.034788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lh_bankssts_area</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.04717</td>\n",
       "      <td>0.010552</td>\n",
       "      <td>0.480861</td>\n",
       "      <td>0.689201</td>\n",
       "      <td>0.040053</td>\n",
       "      <td>0.503797</td>\n",
       "      <td>0.700575</td>\n",
       "      <td>0.049472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>rh_temporalpole_area</td>\n",
       "      <td>0.001878</td>\n",
       "      <td>0.016277</td>\n",
       "      <td>0.025055</td>\n",
       "      <td>0.103885</td>\n",
       "      <td>0.189095</td>\n",
       "      <td>0.065579</td>\n",
       "      <td>1.124799</td>\n",
       "      <td>1.080493</td>\n",
       "      <td>0.237111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>rh_temporalpole_thickness</td>\n",
       "      <td>0.077093</td>\n",
       "      <td>0.088844</td>\n",
       "      <td>0.050545</td>\n",
       "      <td>0.63518</td>\n",
       "      <td>0.641686</td>\n",
       "      <td>0.10454</td>\n",
       "      <td>0.445646</td>\n",
       "      <td>0.45904</td>\n",
       "      <td>0.0543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>rh_thalamus</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.404682</td>\n",
       "      <td>0.024247</td>\n",
       "      <td>0.412486</td>\n",
       "      <td>1.21737</td>\n",
       "      <td>0.224804</td>\n",
       "      <td>0.033622</td>\n",
       "      <td>0.422258</td>\n",
       "      <td>0.324009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>rh_transversetemporal_area</td>\n",
       "      <td>0.136983</td>\n",
       "      <td>0.204541</td>\n",
       "      <td>0.053655</td>\n",
       "      <td>0.011757</td>\n",
       "      <td>0.333466</td>\n",
       "      <td>0.053689</td>\n",
       "      <td>0.887465</td>\n",
       "      <td>1.319851</td>\n",
       "      <td>0.104478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>rh_transversetemporal_thickness</td>\n",
       "      <td>0.019621</td>\n",
       "      <td>0.054384</td>\n",
       "      <td>0.023512</td>\n",
       "      <td>0.195833</td>\n",
       "      <td>0.182213</td>\n",
       "      <td>0.054203</td>\n",
       "      <td>0.465541</td>\n",
       "      <td>0.386393</td>\n",
       "      <td>0.092807</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>154 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Unnamed: 0       HCP        Unnamed: 2  \\\n",
       "0                            Feature     Lasso  Gaussian Process   \n",
       "1                               etiv   1.24636          3.449212   \n",
       "2                  lh_accumbens_area  0.039937          0.301591   \n",
       "3                        lh_amygdala  0.000064          0.060219   \n",
       "4                   lh_bankssts_area  0.000135           0.04717   \n",
       "..                               ...       ...               ...   \n",
       "149             rh_temporalpole_area  0.001878          0.016277   \n",
       "150        rh_temporalpole_thickness  0.077093          0.088844   \n",
       "151                      rh_thalamus  0.000069          0.404682   \n",
       "152       rh_transversetemporal_area  0.136983          0.204541   \n",
       "153  rh_transversetemporal_thickness  0.019621          0.054384   \n",
       "\n",
       "                      Unnamed: 3    CamCAN        Unnamed: 5  \\\n",
       "0    Gradient Boosting Regressor     Lasso  Gaussian Process   \n",
       "1                       0.108937  7.714287          8.831332   \n",
       "2                       0.025911  0.391047          0.079653   \n",
       "3                        0.01316  1.233872          1.531566   \n",
       "4                       0.010552  0.480861          0.689201   \n",
       "..                           ...       ...               ...   \n",
       "149                     0.025055  0.103885          0.189095   \n",
       "150                     0.050545   0.63518          0.641686   \n",
       "151                     0.024247  0.412486           1.21737   \n",
       "152                     0.053655  0.011757          0.333466   \n",
       "153                     0.023512  0.195833          0.182213   \n",
       "\n",
       "                      Unnamed: 6       IXI        Unnamed: 8  \\\n",
       "0    Gradient Boosting Regressor     Lasso  Gaussian Process   \n",
       "1                        0.72565  4.306448          4.933209   \n",
       "2                       0.252782  0.492026          0.258993   \n",
       "3                       0.314019   0.48063          1.126055   \n",
       "4                       0.040053  0.503797          0.700575   \n",
       "..                           ...       ...               ...   \n",
       "149                     0.065579  1.124799          1.080493   \n",
       "150                      0.10454  0.445646           0.45904   \n",
       "151                     0.224804  0.033622          0.422258   \n",
       "152                     0.053689  0.887465          1.319851   \n",
       "153                     0.054203  0.465541          0.386393   \n",
       "\n",
       "                      Unnamed: 9  \n",
       "0    Gradient Boosting Regressor  \n",
       "1                       0.225736  \n",
       "2                       0.481662  \n",
       "3                       0.034788  \n",
       "4                       0.049472  \n",
       "..                           ...  \n",
       "149                     0.237111  \n",
       "150                       0.0543  \n",
       "151                     0.324009  \n",
       "152                     0.104478  \n",
       "153                     0.092807  \n",
       "\n",
       "[154 rows x 10 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sheet_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cbba94f3-976f-4816-af26-ba0d939034f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_name = df_sheet_3.iloc[:, 0]\n",
    "hcp_exp = df_sheet_3.iloc[:, 1:4]\n",
    "cc_exp = df_sheet_3.iloc[:, 4:7]\n",
    "ixi_exp = df_sheet_3.iloc[:, 7:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0789bded-10fd-4ec1-a134-68b541189acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "hcp_exp = pd.concat([feature_name, hcp_exp], axis=1)\n",
    "cc_exp = pd.concat([feature_name, cc_exp], axis=1)\n",
    "ixi_exp = pd.concat([feature_name, ixi_exp], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4f85977-4087-4f11-951c-6a3234ee4788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Lasso</th>\n",
       "      <th>Gaussian Process</th>\n",
       "      <th>Gradient Boosting Regressor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>etiv</td>\n",
       "      <td>1.24636</td>\n",
       "      <td>3.449212</td>\n",
       "      <td>0.108937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lh_accumbens_area</td>\n",
       "      <td>0.039937</td>\n",
       "      <td>0.301591</td>\n",
       "      <td>0.025911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lh_amygdala</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.060219</td>\n",
       "      <td>0.01316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lh_bankssts_area</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.04717</td>\n",
       "      <td>0.010552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lh_bankssts_thickness</td>\n",
       "      <td>0.011672</td>\n",
       "      <td>0.114803</td>\n",
       "      <td>0.025919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>rh_temporalpole_area</td>\n",
       "      <td>0.001878</td>\n",
       "      <td>0.016277</td>\n",
       "      <td>0.025055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>rh_temporalpole_thickness</td>\n",
       "      <td>0.077093</td>\n",
       "      <td>0.088844</td>\n",
       "      <td>0.050545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>rh_thalamus</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.404682</td>\n",
       "      <td>0.024247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>rh_transversetemporal_area</td>\n",
       "      <td>0.136983</td>\n",
       "      <td>0.204541</td>\n",
       "      <td>0.053655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>rh_transversetemporal_thickness</td>\n",
       "      <td>0.019621</td>\n",
       "      <td>0.054384</td>\n",
       "      <td>0.023512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>153 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Feature     Lasso Gaussian Process  \\\n",
       "1                               etiv   1.24636         3.449212   \n",
       "2                  lh_accumbens_area  0.039937         0.301591   \n",
       "3                        lh_amygdala  0.000064         0.060219   \n",
       "4                   lh_bankssts_area  0.000135          0.04717   \n",
       "5              lh_bankssts_thickness  0.011672         0.114803   \n",
       "..                               ...       ...              ...   \n",
       "149             rh_temporalpole_area  0.001878         0.016277   \n",
       "150        rh_temporalpole_thickness  0.077093         0.088844   \n",
       "151                      rh_thalamus  0.000069         0.404682   \n",
       "152       rh_transversetemporal_area  0.136983         0.204541   \n",
       "153  rh_transversetemporal_thickness  0.019621         0.054384   \n",
       "\n",
       "    Gradient Boosting Regressor  \n",
       "1                      0.108937  \n",
       "2                      0.025911  \n",
       "3                       0.01316  \n",
       "4                      0.010552  \n",
       "5                      0.025919  \n",
       "..                          ...  \n",
       "149                    0.025055  \n",
       "150                    0.050545  \n",
       "151                    0.024247  \n",
       "152                    0.053655  \n",
       "153                    0.023512  \n",
       "\n",
       "[153 rows x 4 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hcp_header = hcp_exp.iloc[0]\n",
    "hcp_exp = hcp_exp[1:]\n",
    "hcp_exp.rename(columns=hcp_header, inplace=True)\n",
    "hcp_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "686d151e-db4d-4e52-9cab-fd9165783040",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_header = cc_exp.iloc[0]\n",
    "cc_exp = cc_exp[1:]\n",
    "cc_exp.rename(columns=cc_header, inplace=True)\n",
    "\n",
    "ixi_header = ixi_exp.iloc[0]\n",
    "ixi_exp = ixi_exp[1:]\n",
    "ixi_exp.rename(columns=ixi_header, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dd694e59-bda2-4e97-92e9-0ffaa38d16b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hcp_exp.to_csv('./feat_imp/hcp_exp.csv')\n",
    "ixi_exp.to_csv('./feat_imp/ixi_exp.csv')\n",
    "cc_exp.to_csv('./feat_imp/cc_exp.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140d4e0b-687b-44a8-b6dc-50188104a3c4",
   "metadata": {},
   "source": [
    "## HCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b03ee2f8-50bf-487d-aede-80f490c95606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------------------------------\n",
      "Configuration:\n",
      "data:\n",
      "  parcellation: CAMCAN\n",
      "paths:\n",
      "  datapath: C:/Users/HYUK/Desktop/Brain_Age_Revision_SHAP/data/\n",
      "  genpath: C:/Users/HYUK/Desktop/Brain_Age_Revision_SHAP/data/generated_data/\n",
      "  results: C:/Users/HYUK/Desktop/Brain_Age_Revision_SHAP/results/\n",
      "preproc:\n",
      "  combat: false\n",
      "  pca: false\n",
      "  pca_comps: 0.9\n",
      "  regress: false\n",
      "\n",
      "---------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"config.yaml\", 'r') as ymlfile:\n",
    "    cfg = yaml.safe_load(ymlfile)\n",
    "print('')\n",
    "print('---------------------------------------------------------')\n",
    "print('Configuration:')\n",
    "print(yaml.dump(cfg, default_flow_style=False, default_style=''))\n",
    "print('---------------------------------------------------------')\n",
    "print('')\n",
    "\n",
    "# set paths\n",
    "datapath = cfg['paths']['datapath']\n",
    "metricpath = datapath + 'surfaces/'\n",
    "outpath = cfg['paths']['results']\n",
    "genpath = cfg['paths']['genpath']\n",
    "\n",
    "# other params - whether to regress out global metrics and run PCA\n",
    "preprocessing_params = cfg['preproc']\n",
    "regress = 'Corrected' if preprocessing_params['regress'] else 'Raw'\n",
    "run_pca = 'PCA' if preprocessing_params['pca'] else 'noPCA'\n",
    "run_combat = 'Combat' if preprocessing_params['combat'] else 'noCombat'\n",
    "\n",
    "# cortical parcellation\n",
    "parc = cfg['data']['parcellation']\n",
    "\n",
    "# k-fold CV params\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42) # n_split : 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d92c6857-b5ac-4d06-af2e-fdab1049206f",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_data = pd.read_csv('./data/hcp_train.csv')\n",
    "n_subs = 890\n",
    "n_features = 153\n",
    "num_of_models = 3\n",
    "num_folds = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "72bb4ffc-58ab-4d94-b542-23be73f2cc5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Lasso</th>\n",
       "      <th>Gaussian Process</th>\n",
       "      <th>Gradient Boosting Regressor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>etiv</td>\n",
       "      <td>1.246360</td>\n",
       "      <td>3.449212</td>\n",
       "      <td>0.108937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lh_accumbens_area</td>\n",
       "      <td>0.039937</td>\n",
       "      <td>0.301591</td>\n",
       "      <td>0.025911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lh_amygdala</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.060219</td>\n",
       "      <td>0.013160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lh_bankssts_area</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.047170</td>\n",
       "      <td>0.010552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lh_bankssts_thickness</td>\n",
       "      <td>0.011672</td>\n",
       "      <td>0.114803</td>\n",
       "      <td>0.025919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Feature     Lasso  Gaussian Process  \\\n",
       "1                   etiv  1.246360          3.449212   \n",
       "2      lh_accumbens_area  0.039937          0.301591   \n",
       "3            lh_amygdala  0.000064          0.060219   \n",
       "4       lh_bankssts_area  0.000135          0.047170   \n",
       "5  lh_bankssts_thickness  0.011672          0.114803   \n",
       "\n",
       "   Gradient Boosting Regressor  \n",
       "1                     0.108937  \n",
       "2                     0.025911  \n",
       "3                     0.013160  \n",
       "4                     0.010552  \n",
       "5                     0.025919  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hcp_exp = pd.read_csv('./feat_imp/hcp_exp.csv', index_col=0)\n",
    "hcp_exp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "af22d819-2a35-4e2b-aaf2-8dcf8622c15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hcp_lasso = hcp_exp.loc[:, ['Feature','Lasso']]\n",
    "hcp_gpr = hcp_exp.loc[:, ['Feature','Gaussian Process']]\n",
    "hcp_gbm = hcp_exp.loc[:, ['Feature','Gradient Boosting Regressor']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cbee03bf-671b-4584-b180-35e4d9abe88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hcp_lasso_sort = hcp_lasso.sort_values(by='Lasso', ascending=False)\n",
    "hcp_gpr_sort = hcp_gpr.sort_values(by='Gaussian Process', ascending=False)\n",
    "hcp_gbm_sort = hcp_gbm.sort_values(by='Gradient Boosting Regressor', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "605c9cc7-efa9-4349-bc9d-0e64d35109dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "hcp_lasso_feat_list = hcp_lasso_sort.Feature.to_list()\n",
    "hcp_gpr_feat_list = hcp_gpr_sort.Feature.to_list()\n",
    "hcp_gbm_feat_list = hcp_gbm_sort.Feature.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5423ea-d569-4354-a296-2eb74019a79e",
   "metadata": {},
   "source": [
    "### HCP - LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "59f30325-8ed6-4d40-aed6-3d8ffccbf608",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 10 features\n",
      "Using 20 features\n",
      "Using 30 features\n",
      "Using 40 features\n",
      "Using 50 features\n",
      "Using 60 features\n",
      "Using 70 features\n",
      "Using 80 features\n",
      "Using 90 features\n",
      "Using 100 features\n",
      "Using 110 features\n",
      "Using 120 features\n",
      "Using 130 features\n",
      "Using 140 features\n",
      "Using 150 features\n"
     ]
    }
   ],
   "source": [
    "# Feature가 하나씩 늘어갈 때마다 어떤 식으로 Metric이 변화하는 지를 저장하는 list\n",
    "uncorr_mae_list = []\n",
    "uncorr_r2_list = []\n",
    "corr_mae_list = []\n",
    "corr_r2_list = []\n",
    "\n",
    "for feature_num in range(1, len(hcp_lasso_feat_list) + 1):\n",
    "    if feature_num % 10 ==0:\n",
    "        print(f\"Using {feature_num} features\") \n",
    "    # for문을 돌면서 Mean Absolute SHAP value가 가장 높은 순서대로 하나씩 추가해가며 \n",
    "    # Model Type 변경시 이 부분 수정 \n",
    "    subject_data_iter = subject_data.loc[:, hcp_lasso_feat_list[:feature_num]]\n",
    "    \n",
    "    # fold마다 생성되는 mae, r2 값 저장 \n",
    "    unmae_fold_list = []\n",
    "    unr2_fold_list = []\n",
    "    mae_fold_list = []\n",
    "    r2_fold_list = []\n",
    "    \n",
    "    for n, (train_idx, test_idx) in enumerate(skf.split(np.arange(n_subs), subject_data.Age)):\n",
    "        #print('')\n",
    "        #print('FOLD {:}:------------------------------------------------'.format(n+1))\n",
    "        \n",
    "        # Data 선언\n",
    "        train_y, test_y = subject_data.Age[train_idx], subject_data.Age[test_idx]\n",
    "        # train_x, test_x = subject_data_iter.drop(['Age', 'Subject'], axis=1), subject_data_iter.drop(['Age', 'Subject'], axis=1)\n",
    "\n",
    "        train_x = subject_data_iter.loc[train_idx]\n",
    "        test_x = subject_data_iter.loc[test_idx]\n",
    "        \n",
    "        # Model 선언\n",
    "        # Model Type 변경시 이 부분 수정 \n",
    "        model = get_linear_model(preprocessing_params)\n",
    "        \n",
    "        # Fitting\n",
    "        model.fit(train_x, train_y)\n",
    "            \n",
    "        # PREDICT \n",
    "        train_predictions = model.predict(train_x)\n",
    "        test_predictions = model.predict(test_x)\n",
    "        \n",
    "        # 각 fold에서 Test sample들에 대한 Prediction\n",
    "        uncorr_preds = test_predictions\n",
    "        corr_preds = correct_age_predictions(train_predictions, train_y, test_predictions, test_y)\n",
    "            \n",
    "        # MAE, R2 계산 \n",
    "        unmae_fold_list.append(mean_absolute_error(test_y, uncorr_preds))\n",
    "        unr2_fold_list.append(r2_score(test_y, uncorr_preds))\n",
    "        mae_fold_list.append(mean_absolute_error(test_y, corr_preds))\n",
    "        r2_fold_list.append(r2_score(test_y, corr_preds))\n",
    "        \n",
    "    # 5 fold를 전부 다 돌았으면, 평균 MAE, R2 list에 저장 \n",
    "    uncorr_mae_list.append(np.mean(unmae_fold_list))\n",
    "    uncorr_r2_list.append(np.mean(unr2_fold_list))\n",
    "    corr_mae_list.append(np.mean(mae_fold_list))\n",
    "    corr_r2_list.append(np.mean(r2_fold_list))\n",
    "    \n",
    "    \n",
    "hcp_lasso_metrics = {'uncorr_mae' : uncorr_mae_list, 'uncorr_r2': uncorr_r2_list, \n",
    "                    'corr_mae':corr_mae_list, 'corr_r2': corr_r2_list}\n",
    "hcp_lasso_metrics = pd.DataFrame(hcp_lasso_metrics)\n",
    "hcp_lasso_metrics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e2a9f5-0767-4a36-bfde-3a8a67c6d5db",
   "metadata": {},
   "source": [
    "### HCP - GPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3e85fe23-df3c-4eb8-9096-ef3c910a7330",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 1 features\n",
      "Using 2 features\n",
      "Using 3 features\n",
      "Using 4 features\n",
      "Using 5 features\n",
      "Using 6 features\n",
      "Using 7 features\n",
      "Using 8 features\n",
      "Using 9 features\n",
      "Using 10 features\n",
      "Using 11 features\n",
      "Using 12 features\n",
      "Using 13 features\n",
      "Using 14 features\n",
      "Using 15 features\n",
      "Using 16 features\n",
      "Using 17 features\n",
      "Using 18 features\n",
      "Using 19 features\n",
      "Using 20 features\n",
      "Using 21 features\n",
      "Using 22 features\n",
      "Using 23 features\n",
      "Using 24 features\n",
      "Using 25 features\n",
      "Using 26 features\n",
      "Using 27 features\n",
      "Using 28 features\n",
      "Using 29 features\n",
      "Using 30 features\n",
      "Using 31 features\n",
      "Using 32 features\n",
      "Using 33 features\n",
      "Using 34 features\n",
      "Using 35 features\n",
      "Using 36 features\n",
      "Using 37 features\n",
      "Using 38 features\n",
      "Using 39 features\n",
      "Using 40 features\n",
      "Using 41 features\n",
      "Using 42 features\n",
      "Using 43 features\n",
      "Using 44 features\n",
      "Using 45 features\n",
      "Using 46 features\n",
      "Using 47 features\n",
      "Using 48 features\n",
      "Using 49 features\n",
      "Using 50 features\n",
      "Using 51 features\n",
      "Using 52 features\n",
      "Using 53 features\n",
      "Using 54 features\n",
      "Using 55 features\n",
      "Using 56 features\n",
      "Using 57 features\n",
      "Using 58 features\n",
      "Using 59 features\n",
      "Using 60 features\n",
      "Using 61 features\n",
      "Using 62 features\n",
      "Using 63 features\n",
      "Using 64 features\n",
      "Using 65 features\n",
      "Using 66 features\n",
      "Using 67 features\n",
      "Using 68 features\n",
      "Using 69 features\n",
      "Using 70 features\n",
      "Using 71 features\n",
      "Using 72 features\n",
      "Using 73 features\n",
      "Using 74 features\n",
      "Using 75 features\n",
      "Using 76 features\n",
      "Using 77 features\n",
      "Using 78 features\n",
      "Using 79 features\n",
      "Using 80 features\n",
      "Using 81 features\n",
      "Using 82 features\n",
      "Using 83 features\n",
      "Using 84 features\n",
      "Using 85 features\n",
      "Using 86 features\n",
      "Using 87 features\n",
      "Using 88 features\n",
      "Using 89 features\n",
      "Using 90 features\n",
      "Using 91 features\n",
      "Using 92 features\n",
      "Using 93 features\n",
      "Using 94 features\n",
      "Using 95 features\n",
      "Using 96 features\n",
      "Using 97 features\n",
      "Using 98 features\n",
      "Using 99 features\n",
      "Using 100 features\n",
      "Using 101 features\n",
      "Using 102 features\n",
      "Using 103 features\n",
      "Using 104 features\n",
      "Using 105 features\n",
      "Using 106 features\n",
      "Using 107 features\n",
      "Using 108 features\n",
      "Using 109 features\n",
      "Using 110 features\n",
      "Using 111 features\n",
      "Using 112 features\n",
      "Using 113 features\n",
      "Using 114 features\n",
      "Using 115 features\n",
      "Using 116 features\n",
      "Using 117 features\n",
      "Using 118 features\n",
      "Using 119 features\n",
      "Using 120 features\n",
      "Using 121 features\n",
      "Using 122 features\n",
      "Using 123 features\n",
      "Using 124 features\n",
      "Using 125 features\n",
      "Using 126 features\n",
      "Using 127 features\n",
      "Using 128 features\n",
      "Using 129 features\n",
      "Using 130 features\n",
      "Using 131 features\n",
      "Using 132 features\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [60]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m model \u001b[38;5;241m=\u001b[39m get_nonlinear_model(preprocessing_params)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Fitting\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# PREDICT \u001b[39;00m\n\u001b[0;32m     35\u001b[0m train_predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(train_x)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\grad_paper\\lib\\site-packages\\sklearn\\pipeline.py:382\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    380\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    381\u001b[0m         fit_params_last_step \u001b[38;5;241m=\u001b[39m fit_params_steps[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m--> 382\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_final_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_last_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\grad_paper\\lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:291\u001b[0m, in \u001b[0;36mGaussianProcessRegressor.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    288\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m iteration \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_restarts_optimizer):\n\u001b[0;32m    289\u001b[0m         theta_initial \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rng\u001b[38;5;241m.\u001b[39muniform(bounds[:, \u001b[38;5;241m0\u001b[39m], bounds[:, \u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m    290\u001b[0m         optima\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 291\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_constrained_optimization\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtheta_initial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    292\u001b[0m         )\n\u001b[0;32m    293\u001b[0m \u001b[38;5;66;03m# Select result from run with minimal (negative) log-marginal\u001b[39;00m\n\u001b[0;32m    294\u001b[0m \u001b[38;5;66;03m# likelihood\u001b[39;00m\n\u001b[0;32m    295\u001b[0m lml_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(itemgetter(\u001b[38;5;241m1\u001b[39m), optima))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\grad_paper\\lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:609\u001b[0m, in \u001b[0;36mGaussianProcessRegressor._constrained_optimization\u001b[1;34m(self, obj_func, initial_theta, bounds)\u001b[0m\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constrained_optimization\u001b[39m(\u001b[38;5;28mself\u001b[39m, obj_func, initial_theta, bounds):\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfmin_l_bfgs_b\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 609\u001b[0m         opt_res \u001b[38;5;241m=\u001b[39m \u001b[43mscipy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    610\u001b[0m \u001b[43m            \u001b[49m\u001b[43mobj_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    611\u001b[0m \u001b[43m            \u001b[49m\u001b[43minitial_theta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    612\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mL-BFGS-B\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    613\u001b[0m \u001b[43m            \u001b[49m\u001b[43mjac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    614\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    615\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    616\u001b[0m         _check_optimize_result(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlbfgs\u001b[39m\u001b[38;5;124m\"\u001b[39m, opt_res)\n\u001b[0;32m    617\u001b[0m         theta_opt, func_min \u001b[38;5;241m=\u001b[39m opt_res\u001b[38;5;241m.\u001b[39mx, opt_res\u001b[38;5;241m.\u001b[39mfun\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\grad_paper\\lib\\site-packages\\scipy\\optimize\\_minimize.py:623\u001b[0m, in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    620\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[0;32m    621\u001b[0m                               \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml-bfgs-b\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_minimize_lbfgsb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    624\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtnc\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[0;32m    627\u001b[0m                          \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\grad_paper\\lib\\site-packages\\scipy\\optimize\\lbfgsb.py:360\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[0;32m    354\u001b[0m task_str \u001b[38;5;241m=\u001b[39m task\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[0;32m    355\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFG\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    356\u001b[0m     \u001b[38;5;66;03m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[0;32m    357\u001b[0m     \u001b[38;5;66;03m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[0;32m    358\u001b[0m     \u001b[38;5;66;03m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[0;32m    359\u001b[0m     \u001b[38;5;66;03m# Overwrite f and g:\u001b[39;00m\n\u001b[1;32m--> 360\u001b[0m     f, g \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_and_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    361\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNEW_X\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;66;03m# new iteration\u001b[39;00m\n\u001b[0;32m    363\u001b[0m     n_iterations \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\grad_paper\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:267\u001b[0m, in \u001b[0;36mScalarFunction.fun_and_grad\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray_equal(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx):\n\u001b[0;32m    266\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_x_impl(x)\n\u001b[1;32m--> 267\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_grad()\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\grad_paper\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:233\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    232\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated:\n\u001b[1;32m--> 233\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    234\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\grad_paper\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:137\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_fun\u001b[1;34m()\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_fun\u001b[39m():\n\u001b[1;32m--> 137\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m \u001b[43mfun_wrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\grad_paper\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:134\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnfev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;66;03m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[1;32m--> 134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\grad_paper\\lib\\site-packages\\scipy\\optimize\\optimize.py:74\u001b[0m, in \u001b[0;36mMemoizeJac.__call__\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, \u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;124;03m\"\"\" returns the the function value \"\"\"\u001b[39;00m\n\u001b[1;32m---> 74\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_if_needed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\grad_paper\\lib\\site-packages\\scipy\\optimize\\optimize.py:68\u001b[0m, in \u001b[0;36mMemoizeJac._compute_if_needed\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(x \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(x)\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m---> 68\u001b[0m     fg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\grad_paper\\lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:263\u001b[0m, in \u001b[0;36mGaussianProcessRegressor.fit.<locals>.obj_func\u001b[1;34m(theta, eval_gradient)\u001b[0m\n\u001b[0;32m    261\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mobj_func\u001b[39m(theta, eval_gradient\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    262\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m eval_gradient:\n\u001b[1;32m--> 263\u001b[0m         lml, grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_marginal_likelihood\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    264\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_gradient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclone_kernel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m    265\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    266\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39mlml, \u001b[38;5;241m-\u001b[39mgrad\n\u001b[0;32m    267\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\grad_paper\\lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:533\u001b[0m, in \u001b[0;36mGaussianProcessRegressor.log_marginal_likelihood\u001b[1;34m(self, theta, eval_gradient, clone_kernel)\u001b[0m\n\u001b[0;32m    530\u001b[0m     kernel\u001b[38;5;241m.\u001b[39mtheta \u001b[38;5;241m=\u001b[39m theta\n\u001b[0;32m    532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m eval_gradient:\n\u001b[1;32m--> 533\u001b[0m     K, K_gradient \u001b[38;5;241m=\u001b[39m \u001b[43mkernel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX_train_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_gradient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    534\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    535\u001b[0m     K \u001b[38;5;241m=\u001b[39m kernel(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_train_)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\grad_paper\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:2169\u001b[0m, in \u001b[0;36mDotProduct.__call__\u001b[1;34m(self, X, Y, eval_gradient)\u001b[0m\n\u001b[0;32m   2167\u001b[0m X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39matleast_2d(X)\n\u001b[0;32m   2168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 2169\u001b[0m     K \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msigma_0\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[0;32m   2170\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2171\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m eval_gradient:\n",
      "File \u001b[1;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36minner\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Feature가 하나씩 늘어갈 때마다 어떤 식으로 Metric이 변화하는 지를 저장하는 list\n",
    "uncorr_mae_list = []\n",
    "uncorr_r2_list = []\n",
    "corr_mae_list = []\n",
    "corr_r2_list = []\n",
    "\n",
    "for feature_num in range(1, len(hcp_gpr_feat_list) + 1):\n",
    "    #if feature_num % 10 ==0:\n",
    "    print(f\"Using {feature_num} features\") \n",
    "    # for문을 돌면서 Mean Absolute SHAP value가 가장 높은 순서대로 하나씩 추가해가며 \n",
    "    # Model Type 변경시 이 부분 수정 \n",
    "    subject_data_iter = subject_data.loc[:, hcp_gpr_feat_list[:feature_num]]\n",
    "    \n",
    "    # fold마다 생성되는 mae, r2 값 저장 \n",
    "    unmae_fold_list = []\n",
    "    unr2_fold_list = []\n",
    "    mae_fold_list = []\n",
    "    r2_fold_list = []\n",
    "    \n",
    "    for n, (train_idx, test_idx) in enumerate(skf.split(np.arange(n_subs), subject_data.Age)):\n",
    "        \n",
    "        # Data 선언\n",
    "        train_y, test_y = subject_data.Age[train_idx], subject_data.Age[test_idx]\n",
    "        train_x = subject_data_iter.loc[train_idx]\n",
    "        test_x = subject_data_iter.loc[test_idx]\n",
    "        \n",
    "        # Model 선언\n",
    "        # Model Type 변경시 이 부분 수정 \n",
    "        model = get_nonlinear_model(preprocessing_params)\n",
    "        \n",
    "        # Fitting\n",
    "        model.fit(train_x, train_y)\n",
    "            \n",
    "        # PREDICT \n",
    "        train_predictions = model.predict(train_x)\n",
    "        test_predictions = model.predict(test_x)\n",
    "        \n",
    "        # 각 fold에서 Test sample들에 대한 Prediction\n",
    "        uncorr_preds = test_predictions\n",
    "        corr_preds = correct_age_predictions(train_predictions, train_y, test_predictions, test_y)\n",
    "            \n",
    "        # MAE, R2 계산 \n",
    "        unmae_fold_list.append(mean_absolute_error(test_y, uncorr_preds))\n",
    "        unr2_fold_list.append(r2_score(test_y, uncorr_preds))\n",
    "        mae_fold_list.append(mean_absolute_error(test_y, corr_preds))\n",
    "        r2_fold_list.append(r2_score(test_y, corr_preds))\n",
    "        \n",
    "    # 5 fold를 전부 다 돌았으면, 평균 MAE, R2 list에 저장 \n",
    "    uncorr_mae_list.append(np.mean(unmae_fold_list))\n",
    "    uncorr_r2_list.append(np.mean(unr2_fold_list))\n",
    "    corr_mae_list.append(np.mean(mae_fold_list))\n",
    "    corr_r2_list.append(np.mean(r2_fold_list))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e354b1a9-0b8b-4e44-a938-446cdc881571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Type 변경시 변수 명 수정 (4군데)\n",
    "hcp_gpr_metrics = {'uncorr_mae' : uncorr_mae_list, 'uncorr_r2': uncorr_r2_list, \n",
    "                    'corr_mae':corr_mae_list, 'corr_r2': corr_r2_list}\n",
    "hcp_gpr_metrics = pd.DataFrame(hcp_gpr_metrics)\n",
    "hcp_gpr_metrics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012b9038-b17f-46ac-bda4-1172089dc798",
   "metadata": {},
   "source": [
    "### HCP - GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465e5fdd-94b0-48c3-8c66-94f209523078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature가 하나씩 늘어갈 때마다 어떤 식으로 Metric이 변화하는 지를 저장하는 list\n",
    "uncorr_mae_list = []\n",
    "uncorr_r2_list = []\n",
    "corr_mae_list = []\n",
    "corr_r2_list = []\n",
    "\n",
    "for feature_num in range(1, len(hcp_gbm_feat_list) + 1):\n",
    "    if feature_num % 10 ==0:\n",
    "        print(f\"Using {feature_num} features\") \n",
    "    # for문을 돌면서 Mean Absolute SHAP value가 가장 높은 순서대로 하나씩 추가해가며 \n",
    "    # Model Type 변경시 이 부분 수정 \n",
    "    subject_data_iter = subject_data.loc[:, hcp_gbm_feat_list[:feature_num]]\n",
    "    \n",
    "    # fold마다 생성되는 mae, r2 값 저장 \n",
    "    unmae_fold_list = []\n",
    "    unr2_fold_list = []\n",
    "    mae_fold_list = []\n",
    "    r2_fold_list = []\n",
    "    \n",
    "    for n, (train_idx, test_idx) in enumerate(skf.split(np.arange(n_subs), subject_data.Age)):\n",
    "        #print('')\n",
    "        #print('FOLD {:}:------------------------------------------------'.format(n+1))\n",
    "        \n",
    "        # Data 선언\n",
    "        train_y, test_y = subject_data.Age[train_idx], subject_data.Age[test_idx]\n",
    "        # train_x, test_x = subject_data_iter.drop(['Age', 'Subject'], axis=1), subject_data_iter.drop(['Age', 'Subject'], axis=1)\n",
    "\n",
    "        train_x = subject_data_iter.loc[train_idx]\n",
    "        test_x = subject_data_iter.loc[test_idx]\n",
    "        \n",
    "        # Model 선언\n",
    "        # Model Type 변경시 이 부분 수정 \n",
    "        model = get_ensemble_model(preprocessing_params)\n",
    "        \n",
    "        # Fitting\n",
    "        model.fit(train_x, train_y)\n",
    "            \n",
    "        # PREDICT \n",
    "        train_predictions = model.predict(train_x)\n",
    "        test_predictions = model.predict(test_x)\n",
    "        \n",
    "        # 각 fold에서 Test sample들에 대한 Prediction\n",
    "        uncorr_preds = test_predictions\n",
    "        corr_preds = correct_age_predictions(train_predictions, train_y, test_predictions, test_y)\n",
    "            \n",
    "        # MAE, R2 계산 \n",
    "        unmae_fold_list.append(mean_absolute_error(test_y, uncorr_preds))\n",
    "        unr2_fold_list.append(r2_score(test_y, uncorr_preds))\n",
    "        mae_fold_list.append(mean_absolute_error(test_y, corr_preds))\n",
    "        r2_fold_list.append(r2_score(test_y, corr_preds))\n",
    "        \n",
    "    # 5 fold를 전부 다 돌았으면, 평균 MAE, R2 list에 저장 \n",
    "    uncorr_mae_list.append(np.mean(unmae_fold_list))\n",
    "    uncorr_r2_list.append(np.mean(unr2_fold_list))\n",
    "    corr_mae_list.append(np.mean(mae_fold_list))\n",
    "    corr_r2_list.append(np.mean(r2_fold_list))\n",
    "    \n",
    "    \n",
    "hcp_gbm_metrics = {'uncorr_mae' : uncorr_mae_list, 'uncorr_r2': uncorr_r2_list, \n",
    "                    'corr_mae':corr_mae_list, 'corr_r2': corr_r2_list}\n",
    "hcp_gbm_metrics = pd.DataFrame(hcp_gbm_metrics)\n",
    "hcp_gbm_metrics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d97d405-8b36-47ec-8346-e0a248f28d3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grad_paper",
   "language": "python",
   "name": "grad_paper"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
